{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a076bfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__() # super(subclass, object of subclass)\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(100, 200)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(200, 10)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "tinymodel = TinyModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d4ba86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model:\n",
      "TinyModel(\n",
      "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('The model:')\n",
    "print(tinymodel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf76d311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Just one layer:\n",
      "Linear(in_features=200, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('\\n\\nJust one layer:')\n",
    "print(tinymodel.linear2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dbca35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model params:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0778,  0.0091,  0.0542,  ...,  0.0343, -0.0817,  0.0525],\n",
      "        [-0.0314,  0.0921,  0.0107,  ...,  0.0764,  0.0614,  0.0881],\n",
      "        [ 0.0228, -0.0400, -0.0715,  ...,  0.0496, -0.0823, -0.0291],\n",
      "        ...,\n",
      "        [ 0.0815, -0.0666,  0.0991,  ...,  0.0823, -0.0525,  0.0591],\n",
      "        [-0.0758,  0.0143, -0.0552,  ..., -0.0375,  0.0494, -0.0348],\n",
      "        [-0.0641,  0.0746, -0.0485,  ...,  0.0546,  0.0883,  0.0809]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0399, -0.0029, -0.0186,  0.0641, -0.0386,  0.0080,  0.0010, -0.0874,\n",
      "        -0.0549, -0.0616,  0.0961,  0.0393, -0.0338,  0.0379,  0.0141, -0.0430,\n",
      "        -0.0948,  0.0365,  0.0779,  0.0842,  0.0293,  0.0836, -0.0201, -0.0993,\n",
      "         0.0110,  0.0529, -0.0682,  0.0092, -0.0283,  0.0538, -0.0029,  0.0510,\n",
      "        -0.0244, -0.0963,  0.0925, -0.0640,  0.0825, -0.0286, -0.0248, -0.0995,\n",
      "        -0.0793, -0.0534,  0.0366,  0.0976, -0.0350, -0.0541,  0.0051, -0.0220,\n",
      "        -0.0164,  0.0982, -0.0176,  0.0921,  0.0575, -0.0946,  0.0928, -0.0242,\n",
      "        -0.0428,  0.0429,  0.0044,  0.0946, -0.0963,  0.0836, -0.0710, -0.0700,\n",
      "         0.0842, -0.0379,  0.0657, -0.0008,  0.0338, -0.0180, -0.0894,  0.0526,\n",
      "        -0.0993,  0.0264, -0.0726,  0.0578, -0.0606, -0.0247, -0.0424,  0.0502,\n",
      "         0.0628, -0.0017,  0.0743,  0.0941, -0.0808, -0.0399, -0.0884,  0.0448,\n",
      "        -0.0878, -0.0908,  0.0942,  0.0106,  0.0022,  0.0181, -0.0749,  0.0063,\n",
      "        -0.0859, -0.0855, -0.0471,  0.0057,  0.0905, -0.0419, -0.0228, -0.0096,\n",
      "         0.0439,  0.0055,  0.0026, -0.0710,  0.0358, -0.0313,  0.0805,  0.0552,\n",
      "        -0.0509,  0.0810, -0.0988, -0.0878,  0.0460, -0.0990, -0.0092, -0.0449,\n",
      "        -0.0315,  0.0963,  0.0727, -0.0630,  0.0240, -0.0831, -0.0381, -0.0721,\n",
      "        -0.0465,  0.0785, -0.0448, -0.0729, -0.0104, -0.0628,  0.0110, -0.0817,\n",
      "         0.0703, -0.0993,  0.0072,  0.0954, -0.0777, -0.0444, -0.0765,  0.0347,\n",
      "         0.0864, -0.0854,  0.0569, -0.0114, -0.0886,  0.0125, -0.0778,  0.0525,\n",
      "         0.0221, -0.0914, -0.0495, -0.0830, -0.0921, -0.0773, -0.0198,  0.0857,\n",
      "        -0.0847,  0.0243, -0.0519, -0.0977, -0.0815, -0.0160,  0.0768, -0.0204,\n",
      "        -0.0282, -0.0938, -0.0393, -0.0333, -0.0463,  0.0056,  0.0018, -0.0476,\n",
      "         0.0268, -0.0365, -0.0383,  0.0625,  0.0797, -0.0635,  0.0981,  0.0184,\n",
      "         0.0248, -0.0523, -0.0509,  0.0443,  0.0060,  0.0935,  0.0348, -0.0671,\n",
      "         0.0157, -0.0681, -0.0753, -0.0809, -0.0225, -0.0781, -0.0209, -0.0789],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0610, -0.0076, -0.0190,  ..., -0.0031, -0.0669,  0.0443],\n",
      "        [-0.0035,  0.0582, -0.0421,  ..., -0.0454,  0.0667, -0.0035],\n",
      "        [ 0.0275, -0.0473, -0.0613,  ...,  0.0398, -0.0528, -0.0570],\n",
      "        ...,\n",
      "        [-0.0408, -0.0390, -0.0498,  ..., -0.0577, -0.0040,  0.0319],\n",
      "        [ 0.0154, -0.0466, -0.0187,  ..., -0.0294, -0.0013, -0.0098],\n",
      "        [-0.0307, -0.0203, -0.0046,  ..., -0.0028,  0.0286,  0.0323]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0350,  0.0416,  0.0659,  0.0625,  0.0465, -0.0030, -0.0293,  0.0682,\n",
      "         0.0487,  0.0285], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('\\n\\nModel params:')\n",
    "for param in tinymodel.parameters():\n",
    "    print(param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59dc0e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Layer params:\n",
      "Parameter containing:\n",
      "tensor([[-0.0610, -0.0076, -0.0190,  ..., -0.0031, -0.0669,  0.0443],\n",
      "        [-0.0035,  0.0582, -0.0421,  ..., -0.0454,  0.0667, -0.0035],\n",
      "        [ 0.0275, -0.0473, -0.0613,  ...,  0.0398, -0.0528, -0.0570],\n",
      "        ...,\n",
      "        [-0.0408, -0.0390, -0.0498,  ..., -0.0577, -0.0040,  0.0319],\n",
      "        [ 0.0154, -0.0466, -0.0187,  ..., -0.0294, -0.0013, -0.0098],\n",
      "        [-0.0307, -0.0203, -0.0046,  ..., -0.0028,  0.0286,  0.0323]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0350,  0.0416,  0.0659,  0.0625,  0.0465, -0.0030, -0.0293,  0.0682,\n",
      "         0.0487,  0.0285], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('\\n\\nLayer params:')\n",
    "for param in tinymodel.linear2.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adeabaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = torch.nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ddcc978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3)\n",
    "        self.channel_mult1 = nn.Parameter(torch.ones(8, requires_grad=True))\n",
    "        h1 = self.channel_mult1.register_hook(lambda grad: torch.round(grad))\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3)\n",
    "        self.channel_mult2 = nn.Parameter(torch.ones(8*2, requires_grad=True))\n",
    "        h2 = self.channel_mult2.register_hook(lambda grad: torch.round(grad))\n",
    "        self.linear1 = nn.Linear(16 * 28 * 28, 128) \n",
    "        self.linear2 = nn.Linear(128, 10)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.conv1(x))\n",
    "        x = x * torch.round(self.channel_mult1.view(1, -1, 1, 1))\n",
    "        x = self.activation(self.conv2(x))\n",
    "        x = x * torch.round(self.channel_mult2.view(1, -1, 1, 1))\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = self.activation(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "754f640f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = net(torch.randn(16, 3,32,32))\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac64e6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
