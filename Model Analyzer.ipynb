{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a0da01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "from collections import defaultdict, OrderedDict\n",
    "import ipdb\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import *\n",
    "from torchvision.transforms import *\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab78cb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "image_size = 32\n",
    "transforms = {\n",
    "    \"train\": Compose([\n",
    "        RandomCrop(image_size, padding=4),\n",
    "        RandomHorizontalFlip(),\n",
    "        ToTensor(),\n",
    "    ]),\n",
    "    \"test\": ToTensor(),\n",
    "}\n",
    "dataset = {}\n",
    "for split in [\"train\", \"test\"]:\n",
    "  dataset[split] = CIFAR10(\n",
    "    root=\"data/cifar10\",\n",
    "    train=(split == \"train\"),\n",
    "    download=True,\n",
    "    transform=transforms[split],\n",
    "  )\n",
    "dataloader = {}\n",
    "for split in ['train', 'test']:\n",
    "  dataloader[split] = DataLoader(\n",
    "    dataset[split],\n",
    "    batch_size=512,\n",
    "    shuffle=(split == 'train'),\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9df72568",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def name_fixer(names):\n",
    "    \"\"\"\n",
    "    Fix the names by removing the indices in square brackets.\n",
    "    Args:\n",
    "      names (list): List of names.\n",
    "\n",
    "    Returns:\n",
    "      list: List of fixed names.\n",
    "    \"\"\"\n",
    "    return_list = []\n",
    "    for string in names:\n",
    "        matches = re.finditer(r'\\.\\[(\\d+)\\]', string)\n",
    "        pop_list = [m.start(0) for m in matches]\n",
    "        pop_list.sort(reverse=True)\n",
    "        if len(pop_list) > 0:\n",
    "            string = list(string)\n",
    "            for pop_id in pop_list:\n",
    "                string.pop(pop_id)\n",
    "            string = ''.join(string)\n",
    "        return_list.append(string)\n",
    "    return return_list\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    ARCH = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "        counts = defaultdict(int)\n",
    "\n",
    "        def add(name: str, layer: nn.Module) -> None:\n",
    "            layers.append((f\"{name}{counts[name]}\", layer))\n",
    "            counts[name] += 1\n",
    "\n",
    "        in_channels = 3\n",
    "        for x in self.ARCH:\n",
    "            if x != 'M':\n",
    "                # conv-bn-relu\n",
    "                add(\"conv\", nn.Conv2d(in_channels, x, 3, padding=1, bias=False))\n",
    "                add(\"bn\", nn.BatchNorm2d(x))\n",
    "                add(\"relu\", nn.ReLU(True))\n",
    "                in_channels = x\n",
    "            else:\n",
    "                # maxpool\n",
    "                add(\"pool\", nn.MaxPool2d(2))\n",
    "\n",
    "        self.backbone = nn.Sequential(OrderedDict(layers))\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        # backbone: [N, 3, 32, 32] => [N, 512, 2, 2]\n",
    "        x = self.backbone(x)\n",
    "\n",
    "        # avgpool: [N, 512, 2, 2] => [N, 512]\n",
    "        x = x.mean([2, 3])\n",
    "\n",
    "        # classifier: [N, 512] => [N, 10]\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "fusing_layers = [\n",
    "    'Conv2d',\n",
    "    'BatchNorm2d',\n",
    "    'ReLU',\n",
    "    'Linear',\n",
    "    'BatchNorm1d',\n",
    "]\n",
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "def get_all_layers(model, parent_name=''):\n",
    "    layers = []\n",
    "    for name, module in model.named_children():\n",
    "        full_name = f\"{parent_name}.{name}\" if parent_name else name\n",
    "        test_name = \"model.\" + full_name\n",
    "        try:\n",
    "            eval(test_name)\n",
    "            layers.append((full_name, module))\n",
    "        except:\n",
    "            layers.append((reformat_layer_name(full_name), module))\n",
    "        if isinstance(module, nn.Module):\n",
    "            layers.extend(get_all_layers(module, parent_name=full_name))\n",
    "    return layers\n",
    "\n",
    "\n",
    "def reformat_layer_name(str_data):\n",
    "    try:\n",
    "        split_data = str_data.split('.')\n",
    "        for ind in range(len(split_data)):\n",
    "            data = split_data[ind]\n",
    "            if (data.isdigit()):\n",
    "                split_data[ind] = \"[\" + data + \"]\"\n",
    "        final_string = '.'.join(split_data)\n",
    "\n",
    "        iters_a = re.finditer(r'[a-zA-Z]\\.\\[', final_string)\n",
    "        indices = [m.start(0) + 1 for m in iters_a]\n",
    "        iters = re.finditer(r'\\]\\.\\[', final_string)\n",
    "        indices.extend([m.start(0) + 1 for m in iters])\n",
    "\n",
    "        final_string = list(final_string)\n",
    "        final_string = [final_string[i] for i in range(len(final_string)) if i not in indices]\n",
    "\n",
    "        str_data = ''.join(final_string)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return str_data\n",
    "\n",
    "\n",
    "def summary_string_fixed(model, all_layers, input_size, model_name=None, batch_size=-1, dtypes=None):\n",
    "    if dtypes is None:\n",
    "        dtypes = [torch.FloatTensor] * len(input_size)\n",
    "\n",
    "    def register_hook(module, module_idx):\n",
    "        def hook(module, input, output):\n",
    "            nonlocal module_idx\n",
    "            m_key = all_layers[module_idx][0]\n",
    "            m_key = model_name + \".\" + m_key\n",
    "\n",
    "            try:\n",
    "                eval(m_key)\n",
    "            except:\n",
    "                m_key = name_fixer([m_key])[0]\n",
    "\n",
    "            summary[m_key] = OrderedDict()\n",
    "            summary[m_key][\"type\"] = str(type(module)).split('.')[-1][:-2]\n",
    "            summary[m_key][\"x\"] = input\n",
    "            summary[m_key][\"input_shape\"] = list(input[0].size())\n",
    "            summary[m_key][\"input_shape\"][0] = batch_size\n",
    "\n",
    "            if isinstance(output, (list, tuple)):\n",
    "                summary[m_key][\"y\"] = [\n",
    "                    [-1] + list(o)[1:] for o in output\n",
    "                ]\n",
    "                summary[m_key][\"output_shape\"] = [\n",
    "                    [-1] + list(o.size())[1:] for o in output\n",
    "                ]\n",
    "            else:\n",
    "                summary[m_key][\"y\"] = list(output)\n",
    "\n",
    "\n",
    "                summary[m_key][\"output_shape\"] = list(output.size())\n",
    "                summary[m_key][\"output_shape\"][0] = batch_size\n",
    "\n",
    "            params = 0\n",
    "            if hasattr(module, \"weight\") and hasattr(module.weight, \"size\"):\n",
    "                summary[m_key][\"w\"] = module.weight\n",
    "                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n",
    "                summary[m_key][\"trainable\"] = module.weight.requires_grad\n",
    "                summary[m_key][\"weight_shape\"] = module.weight.shape\n",
    "            if hasattr(module, \"bias\") and hasattr(module.bias, \"size\"):\n",
    "                summary[m_key][\"b\"] = module.bias\n",
    "                params += torch.prod(torch.LongTensor(list(module.bias.size())))\n",
    "            summary[m_key][\"nb_params\"] = params\n",
    "\n",
    "        if (\n",
    "                not isinstance(module, nn.Sequential)\n",
    "                and not isinstance(module, nn.ModuleList)\n",
    "        ):\n",
    "            hooks.append(module.register_forward_hook(hook))\n",
    "\n",
    "    if isinstance(input_size, tuple):\n",
    "        input_size = [input_size]\n",
    "\n",
    "    x = [torch.rand( *in_size).type(dtype)\n",
    "         for in_size, dtype in zip(input_size, dtypes)]\n",
    "\n",
    "    summary = OrderedDict()\n",
    "    hooks = []\n",
    "\n",
    "    for module_idx, (layer_name, module) in enumerate(all_layers):\n",
    "        register_hook(module, module_idx)\n",
    "\n",
    "    model(*x)\n",
    "\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "def get_input_channel_importance(weight):\n",
    "    importances = []\n",
    "    for i_c in range(weight.shape[1]):\n",
    "        channel_weight = weight.detach()[:, i_c]\n",
    "        importance = torch.norm(channel_weight)\n",
    "        importances.append(importance.view(1))\n",
    "    return torch.cat(importances)\n",
    "\n",
    "\n",
    "def get_importance(layer, sparsity):\n",
    "    sorted_indices = torch.argsort(get_input_channel_importance(layer.weight), descending=True)\n",
    "    n_keep = int(round(len(sorted_indices) * (1.0 - sparsity)))\n",
    "    indices_to_keep = sorted_indices[:n_keep]\n",
    "    return indices_to_keep\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def prune_cwp(model, pruning_ratio_list):\n",
    "    \n",
    "    pruned_model = copy.deepcopy(model)\n",
    "    \n",
    "\n",
    "    def get_layer_name(obj):\n",
    "        if isinstance(obj, list):\n",
    "            layer_list = []\n",
    "            for internal_layer in obj:\n",
    "                layer_list.append(eval(internal_layer.replace('model', 'pruned_model')))\n",
    "            return layer_list\n",
    "        else:\n",
    "            nonlocal pruned_model\n",
    "            return eval(obj.replace('model', 'pruned_model'))\n",
    "\n",
    "    for list_ind in range(len(possible_indices_ranges)):\n",
    "        sparsity = pruning_ratio_list[list_ind]\n",
    "        layer_list = np.asarray(possible_indices_ranges[list_ind])\n",
    "\n",
    "        prev_conv = get_layer_name(layer_list[0, 0])\n",
    "        prev_bn = get_layer_name(layer_list[0, 1])\n",
    "        next_convs = [c for c in get_layer_name(list(layer_list[1:, 0]))]\n",
    "        next_bns = [b for b in get_layer_name(list(layer_list[1:-1, 1]))]  # Avoid last 0\n",
    "\n",
    "        if (len(next_bns) == 0):\n",
    "            iter_layers = zip([prev_conv, prev_bn], [next_convs, []])\n",
    "        else:\n",
    "            iter_layers = zip([prev_conv, prev_bn], [next_convs, next_bns])\n",
    "\n",
    "        importance_list_indices = get_importance(layer=next_convs[-1], sparsity=sparsity)\n",
    "\n",
    "        def prune_bn(layer, importance_list_indices):\n",
    "\n",
    "            layer.weight.set_(layer.weight.detach()[importance_list_indices])\n",
    "            layer.bias.set_(layer.bias.detach()[importance_list_indices])\n",
    "            layer.running_mean.set_(layer.running_mean.detach()[importance_list_indices])\n",
    "            layer.running_var.set_(layer.running_var.detach()[importance_list_indices])\n",
    "\n",
    "        for prev_layer, next_layers in iter_layers:\n",
    "            if(prev_layer != 0): #No BatchNorm Used:\n",
    "                \n",
    "                if (str(type(prev_layer)).split('.')[-1][:-2] == 'BatchNorm2d'):  # BatchNorm2d\n",
    "                    prune_bn(prev_layer, importance_list_indices)\n",
    "                else:\n",
    "                    prev_layer.weight.set_(prev_conv.weight.detach()[importance_list_indices, :])\n",
    "                    if prev_layer.bias is not None:\n",
    "                                bias_shape = prev_layer.weight.shape[0]\n",
    "                                prev_layer.bias = nn.Parameter(prev_layer.bias[:bias_shape])\n",
    "                    \n",
    "\n",
    "            if (len(next_layers) != 0):\n",
    "                for next_layer in next_layers:\n",
    "                    if (str(type(next_layer)).split('.')[-1][:-2] == 'BatchNorm2d'):  # BatchNorm2d\n",
    "                        prune_bn(next_layer, importance_list_indices)\n",
    "                    else:\n",
    "                        if (next_layer.weight.shape[1] == 1):\n",
    "                            \n",
    "\n",
    "                            next_layer.weight.set_(next_layer.weight.detach()[importance_list_indices, :])\n",
    "                            number_of_channels = len(importance_list_indices)\n",
    "                            next_layer.groups = number_of_channels\n",
    "                           \n",
    "                            if next_layer.bias is not None:\n",
    "                                bias_shape = next_layer.weight.shape[0]\n",
    "                                next_layer.bias = nn.Parameter(next_layer.bias[:bias_shape])\n",
    "     \n",
    "                              \n",
    "                        else:\n",
    "                            \n",
    "                            next_layer.weight.set_(next_layer.weight.detach()[:, importance_list_indices])\n",
    "#                             next_layer.groups = len(importance_list_indices)\n",
    "                            if next_layer.bias is not None:\n",
    "                                bias_shape = next_layer.weight.shape[0]\n",
    "                                next_layer.bias = nn.Parameter(next_layer.bias[:bias_shape])\n",
    "                \n",
    "#                             if(next_layer.bias!=None):\n",
    "#                                 next_layer.bias.set_(next_layer.bias[:next_layer.weight.shape[1]])\n",
    "#                                 print(len(next_layer.bias))\n",
    "\n",
    "    return pruned_model, model\n",
    "\n",
    "\n",
    "def layer_mapping(model):\n",
    "    all_layers = get_all_layers(model)\n",
    "    x,y = next(iter(dataloader['test']))\n",
    "    model_summary = summary_string_fixed(model, all_layers, x.shape, model_name='model')  # , device=\"cuda\")\n",
    "\n",
    "    name_type_shape = []\n",
    "    for key in model_summary.keys():\n",
    "        data = model_summary[key]\n",
    "        if (\"weight_shape\" in data.keys()):\n",
    "            name_type_shape.append([key, data['type'], data['weight_shape'][0]])\n",
    "        else:\n",
    "            name_type_shape.append([key, data['type'], 0 ])\n",
    "    name_type_shape = np.asarray(name_type_shape)\n",
    "\n",
    "    name_list = name_type_shape[:, 0]\n",
    "\n",
    "    r_name_list = np.asarray(name_list)\n",
    "    random_picks = np.random.randint(0, len(r_name_list), 10)\n",
    "    test_name_list = r_name_list[random_picks]\n",
    "    eval_hit = False\n",
    "    for layer in test_name_list:\n",
    "        try:\n",
    "            eval(layer)\n",
    "\n",
    "        except:\n",
    "            eval_hit = True\n",
    "            break\n",
    "    if (eval_hit):\n",
    "        fixed_name_list = name_fixer(r_name_list)\n",
    "        name_type_shape[:, 0] = fixed_name_list\n",
    "\n",
    "    layer_types = name_type_shape[:, 1]\n",
    "    layer_shapes = name_type_shape[:, 2]\n",
    "    mapped_layers = {'model_layer': [], 'Conv2d_BatchNorm2d_ReLU': [], 'Conv2d_BatchNorm2d': [], 'Linear_ReLU': [],\n",
    "                     'Linear_BatchNorm1d': []}\n",
    "\n",
    "    def detect_sequences(lst):\n",
    "        i = 0\n",
    "        while i < len(lst):\n",
    "\n",
    "            if i + 2 < len(lst) and [l for l in lst[i: i + 3]] == [\n",
    "                fusing_layers[0],\n",
    "                fusing_layers[1],\n",
    "                fusing_layers[2],\n",
    "            ]:\n",
    "                \n",
    "#                 test_layer = layer_shapes[i: i + 2]\n",
    "#                 if (np.all(test_layer == test_layer[0])):\n",
    "                mapped_layers['Conv2d_BatchNorm2d_ReLU'].append(\n",
    "                        np.take(name_list, [i for i in range(i, i + 3)]).tolist()\n",
    "                    )\n",
    "                i += 3\n",
    "\n",
    "            elif i + 1 < len(lst) and [l for l in lst[i: i + 2]] == [\n",
    "                fusing_layers[0],\n",
    "                fusing_layers[1],\n",
    "            ]:\n",
    "#                 test_layer = layer_shapes[i: i + 2]\n",
    "#                 if (np.all(test_layer == test_layer[0])):\n",
    "                mapped_layers['Conv2d_BatchNorm2d'].append(\n",
    "                        np.take(name_list, [i for i in range(i, i + 2)]).tolist()\n",
    "                    )\n",
    "                i += 2\n",
    "            # if i + 1 < len(lst) and [ type(l) for l in lst[i:i+2]] == [fusing_layers[0], fusing_layers[2]]:\n",
    "            #     detected_sequences.append(np.take(name_list,[i for i in range(i,i+2)]).tolist())\n",
    "            #     i += 2\n",
    "            # elif i + 1 < len(lst) and [ type(l) for l in lst[i:i+2]] == [fusing_layers[1], fusing_layers[2]]:\n",
    "            #     detected_sequences.append(np.take(name_list,[i for i in range(i,i+2)]).tolist())\n",
    "            #     i += 2\n",
    "            elif i + 1 < len(lst) and [l for l in lst[i: i + 2]] == [\n",
    "                fusing_layers[3],\n",
    "                fusing_layers[2],\n",
    "            ]:\n",
    "                mapped_layers['Linear_ReLU'].append(\n",
    "                    np.take(name_list, [i for i in range(i, i + 2)]).tolist()\n",
    "                )\n",
    "                i += 2\n",
    "            elif i + 1 < len(lst) and [l for l in lst[i: i + 2]] == [\n",
    "                fusing_layers[3],\n",
    "                fusing_layers[4],\n",
    "            ]:\n",
    "                mapped_layers['Linear_BatchNorm1d'].append(\n",
    "                    np.take(name_list, [i for i in range(i, i + 2)]).tolist()\n",
    "                )\n",
    "                i += 2\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "    detect_sequences(layer_types)\n",
    "\n",
    "    for keys, value in mapped_layers.items():\n",
    "        mapped_layers[keys] = np.asarray(mapped_layers[keys])\n",
    "\n",
    "    mapped_layers['name_type_shape'] = name_type_shape\n",
    "    # self.mapped_layers = mapped_layers\n",
    "\n",
    "    # CWP\n",
    "    keys_to_lookout = ['Conv2d_BatchNorm2d_ReLU', 'Conv2d_BatchNorm2d']\n",
    "    pruning_layer_of_interest, qat_layer_of_interest = [], []\n",
    "\n",
    "    # CWP or QAT Fusion Layers\n",
    "    for keys in keys_to_lookout:\n",
    "        data = mapped_layers[keys]\n",
    "        if (len(data) != 0):\n",
    "            qat_layer_of_interest.append(data)\n",
    "    mapped_layers['qat_layers'] = qat_layer_of_interest\n",
    "    mapped_layers['model_summary'] = model_summary\n",
    "\n",
    "    name_list = mapped_layers['name_type_shape'][:, 0]\n",
    "    \n",
    "    w, x, y, b = [], [], [], []\n",
    "    for layer_name in name_list:\n",
    "        x.append(mapped_layers['model_summary'][layer_name]['x'][0])\n",
    "        w.append(mapped_layers['model_summary'][layer_name]['w'])\n",
    "        y.append(torch.stack(mapped_layers['model_summary'][layer_name]['y']))\n",
    "        b.append(mapped_layers['model_summary'][layer_name]['b'])\n",
    " \n",
    "    mapped_layers['catcher'] = {'name_list':name_list, 'x':x,'w':w,'y':y,'b':b}\n",
    "\n",
    "    return mapped_layers\n",
    "\n",
    "\n",
    "# GMP\n",
    "#         layer_of_interest=mapped_layers['name_type_shape'][:,0] # all layers with weights\n",
    "#         Check for all with weights\n",
    "# Wanda\n",
    "\n",
    "def string_fixer(name_list):\n",
    "    for ind in range(len(name_list)):\n",
    "        modified_string = re.sub(r'\\.(\\[)', r'\\1', name_list[ind])\n",
    "        name_list[ind] = modified_string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42ab0ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cwp_possible_layers(layer_name_list):\n",
    "    possible_indices = []\n",
    "    idx = 0\n",
    "    \n",
    "    while idx < len(layer_name_list):\n",
    "        current_value = layer_name_list[idx]\n",
    "        layer_shape = eval(current_value).weight.shape\n",
    "        curr_merge_list = []\n",
    "        curr_merge_list.append([current_value, 0])\n",
    "        hit_catch = False\n",
    "        for internal_idx in range(idx + 1, len(layer_name_list) - 1):\n",
    "            new_layer = layer_name_list[internal_idx]\n",
    "            new_layer_shape = eval(new_layer).weight.shape\n",
    "            if len(new_layer_shape) == 4:\n",
    "                curr_merge_list.append([new_layer, 0])\n",
    "                if layer_shape[0] == new_layer_shape[1]:\n",
    "                    hit_catch = True\n",
    "                    break\n",
    "            elif len(new_layer_shape) == 1:\n",
    "                curr_merge_list[len(curr_merge_list) - 1][1] = new_layer\n",
    "        possible_indices.append(curr_merge_list)\n",
    "        if hit_catch == True:\n",
    "            idx = internal_idx\n",
    "        else:\n",
    "            idx += 1\n",
    "    return possible_indices\n",
    "\n",
    "def detect_sorting_pairs(name_list):\n",
    "    sorting_pairs = []\n",
    "    idx = 0\n",
    "    while idx < len(name_list):\n",
    "        layer_list = [ layer_name for layer_name in name_list[idx:idx+3]]\n",
    "        \n",
    "        if([ type(eval(l)) for l in layer_list] == [nn.Conv2d, nn.BatchNorm2d,nn.Conv2d]):\n",
    "            sorting_pairs.append(layer_list)\n",
    "            idx+=2\n",
    "        elif([ type(eval(l)) for l in layer_list[idx:idx+2]] == [nn.Conv2d, nn.Conv2d]):\n",
    "            sorting_pairs.append(layer_list[idx:idx+2].insert(1,0))\n",
    "            idx+=1\n",
    "        else:\n",
    "            idx+=1\n",
    "    return sorting_pairs\n",
    "\n",
    "\n",
    "def detect_sorting_all_pairs(conv_bn_list):\n",
    "    possible_list = []\n",
    "    idx = 0\n",
    "    start_idx = 0\n",
    "    end_idx = len(conv_bn_list)\n",
    "    while idx < len(conv_bn_list):\n",
    "        first_layer = eval(conv_bn_list[idx])\n",
    "\n",
    "        if(end_idx+1 - start_idx)<=2:\n",
    "            break\n",
    "\n",
    "        elif isinstance(first_layer, nn.Conv2d):\n",
    "            first_layer_shape = first_layer.weight.shape[:2]\n",
    "            start_idx = idx\n",
    "            for end_idx in range(start_idx, len(conv_bn_list)):\n",
    "                compare_layer = eval(conv_bn_list[end_idx])\n",
    "\n",
    "                if isinstance(compare_layer, nn.Conv2d):\n",
    "                    compare_layer_shape = compare_layer.weight.shape[:2]\n",
    "\n",
    "                    if first_layer_shape[0] == compare_layer_shape[1]:\n",
    "                        possible_list.append([eval(i) for i in conv_bn_list[start_idx:end_idx + 1]])\n",
    "                        idx = end_idx\n",
    "                        break\n",
    "\n",
    "        else:  # BatchNorm case\n",
    "            idx += 1\n",
    "            \n",
    "    return possible_list\n",
    "    \n",
    "    \n",
    "# function to sort the channels from important to non-important\n",
    "def get_input_channel_importance(weight):\n",
    "    in_channels = weight.shape[0] if weight.shape[1]==1 else weight.shape[1]\n",
    "    \n",
    "    \n",
    "    importances = []\n",
    "    # compute the importance for each input channel\n",
    "    for i_c in range(in_channels):\n",
    "        if(weight.shape[1]==1):\n",
    "          \n",
    "            channel_weight = weight.detach()[ i_c,:]\n",
    "        else:\n",
    "            channel_weight = weight.detach()[:, i_c]\n",
    "            \n",
    "\n",
    "        importance = torch.norm(channel_weight)\n",
    "\n",
    "        importances.append(importance.view(1))\n",
    "    if(weight.shape[1]==1):\n",
    "        return torch.cat(importances), 0\n",
    "    else:\n",
    "        return torch.cat(importances), 1\n",
    "\n",
    "@torch.no_grad()\n",
    "def apply_channel_sorting(model, layer_lists):\n",
    "    model = copy.deepcopy(model)  # do not modify the original model\n",
    "    \n",
    "    for prev_conv, prev_bn, next_conv in layer_lists:\n",
    "        #check prev_bn is conv or not\n",
    "        if(prev_conv.weight.shape[1]!=1 and next_conv.weight.shape[1]!=1):\n",
    "            importance, dimension = get_input_channel_importance(next_conv.weight)\n",
    "            # sorting from large to small\n",
    "            sort_idx = torch.argsort(importance, descending=True)\n",
    "\n",
    "            # apply to previous conv and its following bn\n",
    "            prev_conv.weight.copy_(torch.index_select(\n",
    "                prev_conv.weight.detach(), 0, sort_idx))\n",
    "            if(prev_bn!=0):\n",
    "                for tensor_name in ['weight', 'bias', 'running_mean', 'running_var']:\n",
    "                    tensor_to_apply = getattr(prev_bn, tensor_name)\n",
    "                    tensor_to_apply.copy_(\n",
    "                        torch.index_select(tensor_to_apply.detach(), 0, sort_idx)\n",
    "                    )\n",
    "\n",
    "            # apply to the next conv input (hint: one line of code)\n",
    "\n",
    "            next_conv.weight.copy_(\n",
    "                torch.index_select(next_conv.weight.detach(), 1, sort_idx))\n",
    "#         else: #Depthwise Convs can be ignored for sorting\n",
    "#             print(\"Ignore Layer for Sorting\")\n",
    "\n",
    "    ###############\n",
    "    \n",
    "#     for layer_list in layer_lists:\n",
    "#         not_last_layers = layer_list[:-1]\n",
    "#         last_layer = layer_list[-1]\n",
    "#         importance, dimension = get_input_channel_importance(last_layer.weight)\n",
    "#         sort_idx = torch.argsort(importance, descending=True)\n",
    "        \n",
    "#         #Conv Conv | Conv Bn Conv | Conv Bn Conv Bn Conv....Conv\n",
    "        \n",
    "#         for layer_idx in range(len(not_last_layers)):\n",
    "#             layer = not_last_layers[layer_idx]     \n",
    "            \n",
    "#             if(layer_idx==0): #First Conv\n",
    "#                 layer.weight.copy_(torch.index_select(layer.weight.detach(), 0, sort_idx))\n",
    "                \n",
    "#             elif(isinstance(layer,nn.Conv2d)): #Next Conv's\n",
    "#                 if(layer.weight.shape[1]==1): #Group Convs\n",
    "#                     continue\n",
    "                        \n",
    "# #                     layer.weight.copy_(torch.index_select(layer.weight.detach(), 0, sort_idx))\n",
    "#                 else:\n",
    "#                      layer.weight.copy_(torch.index_select(layer.weight.detach(), 1, sort_idx))\n",
    "                    \n",
    "#             elif(isinstance(layer,nn.BatchNorm2d)): #Next Bn's\n",
    "#                 for tensor_name in ['weight', 'bias', 'running_mean', 'running_var']:\n",
    "#                     tensor_to_apply = getattr(layer, tensor_name)\n",
    "#                     tensor_to_apply.copy_(torch.index_select(tensor_to_apply.detach(), 0, sort_idx))\n",
    "                \n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da56c42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to sort the channels from important to non-important\n",
    "def broom(weight):\n",
    "    in_channels = weight.shape[1]\n",
    "    importances = []\n",
    "    # compute the importance for each input channel\n",
    "    for i_c in range(weight.shape[1]):\n",
    "        channel_weight = weight.detach()[:, i_c]\n",
    "\n",
    "        importance = torch.norm(channel_weight)\n",
    "\n",
    "        importances.append(importance.view(1))\n",
    "    return torch.cat(importances)\n",
    "@torch.no_grad()\n",
    "def tester(original_model, _):\n",
    "    model = copy.deepcopy(original_model)  # do not modify the original model\n",
    "    # fetch all the conv and bn layers from the backbone\n",
    "    all_convs = [m for m in model.backbone if isinstance(m, nn.Conv2d)]\n",
    "    all_bns = [m for m in model.backbone if isinstance(m, nn.BatchNorm2d)]\n",
    "\n",
    "\n",
    "\n",
    "    mapped_layers = layer_mapping(model)\n",
    "    name_list = mapped_layers['name_type_shape'][:, 0]\n",
    "    type_list = mapped_layers['name_type_shape'][:, 1]\n",
    "    conv_bn_list = name_list[[index for index, layer in enumerate(type_list) if layer in ['Conv2d', 'BatchNorm2d']]]\n",
    "    layer_list = detect_sorting_pairs(conv_bn_list)\n",
    "\n",
    "\n",
    "    i_conv = 0\n",
    "    \n",
    "    for layers in layer_list:\n",
    "        # each channel sorting index, we need to apply it to:\n",
    "        # - the output dimension of the previous conv\n",
    "        # - the previous BN layer\n",
    "        # - the input dimension of the next conv (we compute importance here)\n",
    "        a_r = all_convs[i_conv]\n",
    "        b_r = all_bns[i_conv]\n",
    "        c_r = all_convs[i_conv + 1]\n",
    "        i_conv+=1\n",
    "        prev_conv,prev_bn,next_conv = eval(layers[0]),eval(layers[1]),eval(layers[2])\n",
    "#         ipdb.set_trace()\n",
    "        \n",
    "        print(torch.eq(prev_conv.weight, a_r.weight).all().item())\n",
    "        print(torch.eq(prev_bn.weight, b_r.weight).all().item())\n",
    "        print(torch.eq(next_conv.weight, c_r.weight).all().item())\n",
    "\n",
    "        importance = broom(next_conv.weight)\n",
    "        # sorting from large to small\n",
    "        sort_idx = torch.argsort(importance, descending=True)\n",
    "\n",
    "        # apply to previous conv and its following bn\n",
    "        a_r.weight.copy_(torch.index_select(\n",
    "            a_r.weight.detach(), 0, sort_idx))\n",
    "        prev_conv.weight.copy_(torch.index_select(\n",
    "            prev_conv.weight.detach(), 0, sort_idx))\n",
    "        for tensor_name in ['weight', 'bias', 'running_mean', 'running_var']:\n",
    "            tensor_to_apply = getattr(prev_bn, tensor_name)\n",
    "            tensor_to_apply.copy_(\n",
    "                torch.index_select(tensor_to_apply.detach(), 0, sort_idx)\n",
    "            )\n",
    "            tensor_to_apply_r = getattr(b_r, tensor_name)\n",
    "            tensor_to_apply_r.copy_(\n",
    "                torch.index_select(tensor_to_apply_r.detach(), 0, sort_idx)\n",
    "            )\n",
    "\n",
    "        # apply to the next conv input (hint: one line of code)\n",
    "\n",
    "        next_conv.weight.copy_(\n",
    "            torch.index_select(next_conv.weight.detach(), 1, sort_idx))\n",
    "        c_r.weight.copy_(\n",
    "            torch.index_select(c_r.weight.detach(), 1, sort_idx))\n",
    "#         else:\n",
    "#             print(\"MOP\")\n",
    "\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7585e32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/sathya/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/Users/sathya/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sathya/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Using cache found in /Users/sathya/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/Users/sathya/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# #load the pretrained model\n",
    "\n",
    "# resnet18 = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\n",
    "# densenet = torch.hub.load('pytorch/vision:v0.10.0', 'densenet121', pretrained=False)\n",
    "# super_net = torch.hub.load('mit-han-lab/once-for-all', super_net_name, pretrained=True)\n",
    "\n",
    "super_net_name = \"ofa_supernet_mbv3_w10\" \n",
    "\n",
    "vgg = VGG()\n",
    "checkpoint = torch.load(\"./vgg.cifar.pretrained.pth\",map_location='cpu')\n",
    "vgg.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "mobilenet_v2 = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n",
    "mobilenet_v2.load_state_dict(torch.load(\"./mobilenet_v2-cifar10.pth\", map_location='cpu'))\n",
    "\n",
    "mobilenet_v3 = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v3_small', pretrained=True)\n",
    "\n",
    "\n",
    "# model_list = [vgg, mobilenet_v2, mobilenet_v3 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "723cf801",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Define the convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        # Define the fully connected layers\n",
    "        self.fc1 = nn.Linear(32 * 16 * 16, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Perform convolution, activation, and pooling\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        x = x.view(-1, 32 * 16 * 16)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21540da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model.conv1' 'model.conv2' 'model.fc1' 'model.fc2']\n"
     ]
    }
   ],
   "source": [
    "model = vgg\n",
    "\n",
    "model = copy.deepcopy(model)\n",
    "\n",
    "net = SimpleCNN(10)\n",
    "mapped_layers = layer_mapping(net)\n",
    "name_list = mapped_layers['name_type_shape'][:, 0]\n",
    "type_list = mapped_layers['name_type_shape'][:, 1]\n",
    "print(name_list)\n",
    "# conv_bn_list = name_list[[index for index, layer in enumerate(type_list) if layer in ['Conv2d', 'BatchNorm2d']]]\n",
    "# sorted_conv_list = detect_sorting_pairs(conv_bn_list)\n",
    "# sorted_model = tester(model, 3)\n",
    "\n",
    "# sorted_conv_list = detect_sorting_all_pairs(conv_bn_list)\n",
    "# sorted_model = apply_channel_sorting(model, sorted_conv_lis\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# sorted_model = tester(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b37cdad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name: model.conv1\n",
      "X: torch.Size([512, 3, 32, 32])\n",
      "W: torch.Size([16, 3, 3, 3]) B: torch.Size([16])\n",
      "Y: torch.Size([512, 16, 32, 32])\n",
      "\n",
      "\n",
      "Layer Name: model.conv2\n",
      "X: torch.Size([512, 16, 16, 16])\n",
      "W: torch.Size([32, 16, 3, 3]) B: torch.Size([32])\n",
      "Y: torch.Size([512, 32, 16, 16])\n",
      "\n",
      "\n",
      "Layer Name: model.fc1\n",
      "X: torch.Size([128, 8192])\n",
      "W: torch.Size([512, 8192]) B: torch.Size([512])\n",
      "Y: torch.Size([128, 512])\n",
      "\n",
      "\n",
      "Layer Name: model.fc2\n",
      "X: torch.Size([128, 512])\n",
      "W: torch.Size([10, 512]) B: torch.Size([10])\n",
      "Y: torch.Size([128, 10])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, layer_name in enumerate(mapped_layers['catcher']['name_list']):\n",
    "    print(f\"Layer Name: {layer_name}\")\n",
    "    print(f\"X: {mapped_layers['catcher']['x'][idx].size()}\")\n",
    "    print(f\"W: {mapped_layers['catcher']['w'][idx].size()}\",f\"B: {mapped_layers['catcher']['b'][idx].size()}\")\n",
    "    print(f\"Y: {mapped_layers['catcher']['y'][idx].size()}\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
